{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86120304-e779-4bd4-86f8-dad41f58e6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "import numpy as np\n",
    "\n",
    "# Create a list of integers\n",
    "int_num = list(range(10))  # \n",
    "\n",
    "# Save the matrix to \n",
    "with open('data_int.txt', 'w') as f:\n",
    "    for num in int_num:\n",
    "        f.write(str(num))\n",
    "        print()\n",
    "\n",
    "# Create a 5x5 matrix of floats filled with zeros and save it to the file below\n",
    "Float_M = np.zeros((5, 5), dtype=float)\n",
    "np.savetxt('data_float.txt', Float_M,  fmt='%.2f')\n",
    "\n",
    "# Load the text file\n",
    "with open('data_float.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    \n",
    "# Convert and save the text content to a CSV format\n",
    "csv_content = content.replace(' ', ',')  \n",
    "with open('data.csv', 'w') as file:\n",
    "    file.write(csv_content)\n",
    "\n",
    "### print the text using git bash\n",
    "#cat data_int.txt  \n",
    "#cat data_float.txt  \n",
    "#cat data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ad6c49b-6b55-4652-ac2a-29c276e891d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data: \n",
      " [{'ID': '2', 'JobTitle': 'Investment  Advisor', 'EmailAddress': 'Clint_Thorpe5003@bulaffy.com', 'FirstNameLastName': 'Clint Thorpe', 'CreditCard': '7083-8766-0251-2345', 'CreditCardType': 'American Express'}, {'ID': '12', 'JobTitle': 'Retail Trainee', 'EmailAddress': 'Phillip_Carpenter9505@famism.biz', 'FirstNameLastName': 'Phillip Carpenter', 'CreditCard': '3657-0088-0820-5247', 'CreditCardType': 'American Express'}, {'ID': '28', 'JobTitle': 'Project Manager', 'EmailAddress': 'Russel_Graves1378@extex.org', 'FirstNameLastName': 'Russel Graves', 'CreditCard': '6718-4818-8011-6024', 'CreditCardType': 'American Express'}, {'ID': '39', 'JobTitle': 'Stockbroker', 'EmailAddress': 'Leanne_Newton1268@typill.biz', 'FirstNameLastName': 'Leanne Newton', 'CreditCard': '5438-0816-4166-4847', 'CreditCardType': 'American Express'}, {'ID': '57', 'JobTitle': 'Budget Analyst', 'EmailAddress': 'Tony_Giles1960@iatim.tech', 'FirstNameLastName': 'Tony Giles', 'CreditCard': '8130-3425-7573-7745', 'CreditCardType': 'American Express'}, {'ID': '62', 'JobTitle': 'CNC Operator', 'EmailAddress': 'Owen_Allcott5125@bauros.biz', 'FirstNameLastName': 'Owen Allcott', 'CreditCard': '4156-0107-7210-2630', 'CreditCardType': 'American Express'}, {'ID': '68', 'JobTitle': 'Project Manager', 'EmailAddress': 'Liam_Lynn3280@kideod.biz', 'FirstNameLastName': 'Liam Lynn', 'CreditCard': '7152-3247-6053-2233', 'CreditCardType': 'American Express'}, {'ID': '74', 'JobTitle': 'Dentist', 'EmailAddress': 'Regina_Woodcock5820@yahoo.com', 'FirstNameLastName': 'Regina Woodcock', 'CreditCard': '0208-1753-3870-8002', 'CreditCardType': 'American Express'}, {'ID': '81', 'JobTitle': 'HR Specialist', 'EmailAddress': 'Carter_Wallace9614@atink.com', 'FirstNameLastName': 'Carter Wallace', 'CreditCard': '4256-7201-6717-4322', 'CreditCardType': 'American Express'}, {'ID': '92', 'JobTitle': 'Staffing Consultant', 'EmailAddress': 'Maia_Stark2797@jiman.org', 'FirstNameLastName': 'Maia Stark', 'CreditCard': '3851-1403-1734-6321', 'CreditCardType': 'American Express'}, {'ID': '97', 'JobTitle': 'Stockbroker', 'EmailAddress': 'Ciara_Lomax982@bauros.biz', 'FirstNameLastName': 'Ciara Lomax', 'CreditCard': '3702-3440-2472-5424', 'CreditCardType': 'American Express'}, {'ID': '116', 'JobTitle': 'Staffing Consultant', 'EmailAddress': 'Isabel_Ellwood1475@fuliss.net', 'FirstNameLastName': 'Isabel Ellwood', 'CreditCard': '3738-0882-0066-6683', 'CreditCardType': 'American Express'}, {'ID': '148', 'JobTitle': 'CNC Operator', 'EmailAddress': 'Abdul_Townend2202@infotech44.tech', 'FirstNameLastName': 'Abdul Townend', 'CreditCard': '4224-1226-3557-3448', 'CreditCardType': 'American Express'}, {'ID': '150', 'JobTitle': 'Fabricator', 'EmailAddress': 'Caleb_Poulton1735@atink.com', 'FirstNameLastName': 'Caleb Poulton', 'CreditCard': '8203-6875-5225-0341', 'CreditCardType': 'American Express'}, {'ID': '151', 'JobTitle': 'Restaurant Manager', 'EmailAddress': 'Ronald_Lewis6777@deavo.com', 'FirstNameLastName': 'Ronald Lewis', 'CreditCard': '7212-0155-5014-8471', 'CreditCardType': 'American Express'}, {'ID': '154', 'JobTitle': 'Bellman', 'EmailAddress': 'Faith_Seymour3829@twace.org', 'FirstNameLastName': 'Faith Seymour', 'CreditCard': '4170-5186-6887-6558', 'CreditCardType': 'American Express'}, {'ID': '169', 'JobTitle': 'Assistant Buyer', 'EmailAddress': 'Anthony_Hancock9083@qater.org', 'FirstNameLastName': 'Anthony Hancock', 'CreditCard': '0832-3357-6010-6550', 'CreditCardType': 'American Express'}, {'ID': '176', 'JobTitle': 'Healthcare Specialist', 'EmailAddress': 'Isabella_Willson5478@nanoff.biz', 'FirstNameLastName': 'Isabella Willson', 'CreditCard': '5177-4868-4623-0384', 'CreditCardType': 'American Express'}, {'ID': '182', 'JobTitle': 'Pharmacist', 'EmailAddress': 'Stephanie_Darcy3298@bauros.biz', 'FirstNameLastName': 'Stephanie Darcy', 'CreditCard': '0264-4020-5106-5576', 'CreditCardType': 'American Express'}, {'ID': '199', 'JobTitle': 'Investment  Advisor', 'EmailAddress': 'Ryan_Kennedy5565@corti.com', 'FirstNameLastName': 'Ryan Kennedy', 'CreditCard': '3166-6287-6242-7207', 'CreditCardType': 'American Express'}]\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "import json\n",
    "import csv\n",
    "#Filtering data\n",
    "data = json.load(open('C:\\\\Users\\\\dell\\\\Desktop\\\\data\\\\user_data.json'))\n",
    "filtered = [dict for dict in data if dict['CreditCardType']=='American Express']\n",
    "print(\"Filtered data: \\n\", filtered)\n",
    "\n",
    "#Writing the result in csv file\n",
    "writer = csv.DictWriter(open('filtered.csv', 'a'), filtered[0].keys())\n",
    "for dict in filtered:\n",
    "    writer.writerow(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e92dc2a-7465-4c9d-af6e-5a6b51e7a7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cap-shape  cap-surface  cap-color   bruises      odor  gill-attachment  \\\n",
      "class                                                                           \n",
      "0       3.266160     1.615970   4.581749  0.653992  4.334601         0.954373   \n",
      "1       3.436159     2.055158   4.421859  0.159346  3.940756         0.995403   \n",
      "\n",
      "       gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
      "class                                                    ...   \n",
      "0          0.285171   0.068441    6.622624     0.615970  ...   \n",
      "1          0.028601   0.567926    2.863636     0.514811  ...   \n",
      "\n",
      "       stalk-surface-below-ring  stalk-color-above-ring  \\\n",
      "class                                                     \n",
      "0                      1.798479                6.098859   \n",
      "1                      1.394280                5.512768   \n",
      "\n",
      "       stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
      "class                                                                          \n",
      "0                    6.064639        0.0    1.931559     1.125475   3.007605   \n",
      "1                    5.504597        0.0    2.002043     1.009193   1.522983   \n",
      "\n",
      "       spore-print-color  population   habitat  \n",
      "class                                           \n",
      "0               3.201521    3.283270  1.148289  \n",
      "1               4.021450    4.031665  1.895812  \n",
      "\n",
      "[2 rows x 22 columns]\n",
      "Means DataFrame saved to mushrooms_means.json\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\dell\\\\Desktop\\\\data\\\\mushrooms_categorized.csv\")\n",
    "\n",
    "means = df.groupby([\"class\"]).agg('mean')\n",
    "print(means)\n",
    "\n",
    "# Save the means DataFrame to a JSON file\n",
    "means.to_json(\"C:\\\\Users\\\\dell\\\\Desktop\\\\data\\\\mushrooms_means.json\")\n",
    "\n",
    "print(\"Means DataFrame saved to mushrooms_means.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc565a2-b201-403e-89a1-9e673d3286ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msqlite3\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Connect to the sakila.db database\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43msqlite3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://github.com/zucchett/ScientificComputingWithPython2023/blob/main/06ex_dataio.ipynb.db\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Query the actors table and import the data into a DataFrame\u001b[39;00m\n\u001b[0;32m      8\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM actor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mOperationalError\u001b[0m: unable to open database file"
     ]
    }
   ],
   "source": [
    "#4import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Connect to the sakila.db database\n",
    "conn = sqlite3.connect('https://github.com/zucchett/ScientificComputingWithPython2023/blob/main/06ex_dataio.ipynb.db')\n",
    "\n",
    "# Query the actors table and import the data into a DataFrame\n",
    "query = \"SELECT * FROM actor\"\n",
    "actors_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Count the number of actors with the first name starting with 'A'\n",
    "count_A = len(actors_df[actors_df['first_name'].str.startswith('A')])\n",
    "\n",
    "print(f\"The number of actors with the first name starting with 'A' is: {count_A }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d91f597-8a81-4f32-aae7-b60f06e6d40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55-54-52-56-53-54-55-51-51-55-55-53-50-50-55-49\n",
      "51-50-53-55-56-50-52-55-51-51-53-52-50-50-54-54\n",
      "50-55-50-50-48-48-48-49-52-48-49-49-54-54-53-50\n",
      "48-54-54-49-51-48-54-51-51-55-52-50-51-49-53-48\n",
      "48-52-51-50-49-54-48-56-49-52-54-50-52-55-52-50\n",
      "53-56-50-55-50-48-50-55-56-55-56-53-55-51-48-51\n",
      "53-55-55-52-56-53-50-56-50-48-56-55-49-49-49-55\n",
      "56-49-52-48-49-50-49-48-54-51-53-50-50-56-52-53\n",
      "53-55-54-52-49-49-51-51-55-51-48-49-55-49-48-48\n",
      "54-52-53-54-49-55-51-55-52-49-50-54-54-55-50-54\n",
      "49-50-50-56-56-54-51-49-55-51-56-50-48-48-48-48\n",
      "55-48-53-49-48-49-54-48-53-51-55-52-51-49-54-54\n",
      "48-54-49-56-51-53-56-55-49-54-51-48-54-51-55-54\n",
      "49-53-52-53-53-52-53-52-55-52-52-52-53-54-51-54\n",
      "54-55-51-53-51-49-49-54-51-50-48-50-54-56-51-52\n",
      "55-50-56-55-53-48-49-49-49-53-52-55-56-52-49-51\n",
      "55-48-51-51-50-54-48-55-51-51-50-56-52-50-48-48\n",
      "50-53-54-56-53-50-52-52-49-56-55-52-53-48-50-52\n",
      "49-54-56-52-50-50-53-51-55-53-55-48-55-49-49-56\n",
      "48-54-55-50-50-53-55-54-48-53-55-53-54-54-51-49\n",
      "54-51-51-50-56-51-53-51-56-55-56-55-49-51-52-48\n",
      "49-56-49-51-51-51-54-49-49-49-55-53-52-50-49-49\n",
      "50-52-55-55-54-52-53-48-56-56-52-48-50-51-54-56\n",
      "53-53-49-50-51-53-48-53-50-53-54-51-49-51-50-54\n",
      "51-48-56-51-55-56-56-50-48-54-50-49-48-48-50-53\n",
      "52-53-50-49-53-49-52-56-56-48-52-53-48-51-51-52\n",
      "55-53-54-51-51-54-53-52-56-55-49-51-53-55-56-55\n",
      "56-51-50-52-50-54-54-52-48-52-55-54-53-53-54-49\n",
      "48-53-54-53-50-53-48-52-55-49-54-56-51-53-49-48\n",
      "53-49-48-55-53-53-48-55-49-55-54-55-48-55-51-56\n",
      "50-52-54-50-49-56-50-49-50-52-52-56-49-52-52-51\n",
      "50-55-56-56-48-54-51-56-54-56-54-49-54-53-53-52\n",
      "53-56-53-49-53-56-55-51-53-52-55-52-48-53-52-55\n",
      "48-54-55-48-49-48-48-52-52-48-49-51-50-54-53-53\n",
      "53-56-55-52-53-53-48-54-51-48-52-56-48-56-48-54\n",
      "50-56-48-53-53-52-48-49-56-52-54-50-49-50-54-48\n",
      "53-48-56-51-56-52-48-54-54-51-49-48-49-56-54-50\n",
      "49-48-55-54-49-52-52-53-51-48-49-51-50-50-54-54\n",
      "56-52-52-48-52-56-48-52-52-56-52-52-53-50-55-55\n",
      "52-55-53-56-54-49-52-49-48-54-56-54-49-51-56-55\n",
      "55-53-56-54-48-54-55-53-48-51-49-53-50-53-54-56\n",
      "50-53-52-52-49-50-53-56-55-52-51-50-53-49-54-53\n",
      "51-52-55-52-53-48-50-51-52-52-51-52-53-54-50-54\n",
      "49-52-49-48-48-50-55-48-48-52-51-52-53-48-56-54\n",
      "55-51-49-53-52-52-52-54-49-49-48-52-52-50-49-53\n",
      "48-50-50-52-55-55-52-50-56-51-48-48-48-50-54-54\n",
      "48-49-55-48-50-55-48-48-51-49-52-53-48-54-52-48\n",
      "50-48-48-54-50-52-51-55-56-48-53-52-49-54-48-48\n",
      "56-49-52-50-52-48-53-53-49-55-55-54-48-48-50-54\n",
      "51-48-50-54-55-51-56-48-49-50-52-49-49-48-56-52\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "with open('C:\\\\Users\\\\dell\\\\Desktop\\\\data\\\\credit_card.dat','rb') as file:\n",
    "    while True:\n",
    "        file_content=file.readline()\n",
    "        # read the file dividing the sequences of 6 bits\n",
    "        ints=[]\n",
    "        try:\n",
    "            for i in range(0,19*6,6):\n",
    "                if (i==24 or i==54 or i==84):\n",
    "                    continue\n",
    "                ints.append(int(file_content[i:i+6], 2))\n",
    "        except ValueError:\n",
    "            break\n",
    "        print(\"-\". join(str(j) for j in ints))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc35a48f-d8ba-46c4-8064-dc866f51953a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(binary_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m binary_file:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 23\u001b[0m         word \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m         binary_file\u001b[38;5;241m.\u001b[39mwrite(struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<q\u001b[39m\u001b[38;5;124m'\u001b[39m, word))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Read binary file and print contents\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[55], line 16\u001b[0m, in \u001b[0;36mconvert_to_word\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     13\u001b[0m word \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m row:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Pack values into a single 64-bit word using bitwise shifts and OR operator\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     word \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m word\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "#6\n",
    "# Write data to a binary file\n",
    "\n",
    "import pandas as pd\n",
    "import struct\n",
    "\n",
    "# Read the first 10 lines using Pandas\n",
    "file_path = 'C:\\\\Users\\\\dell\\\\Desktop\\\\data\\\\data_000637.txt'\n",
    "data = pd.read_csv(file_path, nrows=10, header=None, delimiter='\\t')\n",
    "\n",
    "# Function to convert row values to a 64-bit word\n",
    "def convert_to_word(row):\n",
    "    word = 0\n",
    "    for val in row:\n",
    "        # Pack values into a single 64-bit word using bitwise shifts and OR operator\n",
    "        word = (word << 8) | val\n",
    "    return word\n",
    "\n",
    "# Convert and write data to a binary file\n",
    "binary_file_path = 'C:\\\\Users\\\\dell\\\\Desktop\\\\data\\\\data_000637.bin'\n",
    "with open(binary_file_path, 'wb') as binary_file:\n",
    "    for _, row in data.iterrows():\n",
    "        word = convert_to_word(row)\n",
    "        binary_file.write(struct.pack('<q', word))\n",
    "\n",
    "# Read binary file and print contents\n",
    "with open(binary_file_path, 'rb') as binary_file:\n",
    "    content = binary_file.read()\n",
    "    print(content)\n",
    "\n",
    "# Check file sizes\n",
    "import os\n",
    "txt_file_size = os.path.getsize(file_path)\n",
    "bin_file_size = os.path.getsize(binary_file_path)\n",
    "print(f\"Size of text file: {txt_file_size} bytes\")\n",
    "print(f\"Size of binary file: {bin_file_size} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae517d-4202-42c1-99b6-d8078432df3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e83021-8fef-4e32-8b1f-a5868f5a7379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
